\documentclass[margin,line]{resume}
\usepackage[hidelinks]{hyperref}

\begin{document}

\name{Nan Jiang}

\begin{resume}
\section{Contact Information}
\begin{tabular}{@{}p{3.5in}p{3.5in}}
Department of Computer Science  & { Github:} {\tt github.com/jiangnanhugo} \\
Purdue University                 & { E-mail:}  {\tt jiangnan.hugo@gmail.com}  \\
\end{tabular}


\section{Education}
{\bf Beihang University} (BUAA), Beijing, China \hfill {\bf Sept., 2015 - Mar., 2018}\\
Master in Computer Science. Advisor: \underline{\href{http://dblp.uni-trier.de/pers/hd/r/Rong:Wenge}{Wenge Rong}}.\\
Thsis: Exploration of Hierarchical Softmax for Recurrent Language Models. \\
Research Interests: Natural Language Processing, Deep Learning.

{\bf Zhejiang University of Technology} (ZJUT), Zhejiang, China \hfill {\bf Sept., 2011 - Jul., 2015}\\
Bachelor in Computer Science and Technology \& Automation (double degree). \\
\space Major GPA: 4.0, Top 1 of 58.


\section{Publications}
Zhen Xu, \textbf{Nan Jiang} and Bowen Wu. LSDSCC: A Large Scale Domain-Specific Conversational Corpus for Response Generation with Diversity Oriented Evaluation Metrics. North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), 2018.

\textbf{Nan Jiang}, Wenge Rong, Min Gao, Yikang Shen and Zhang Xiong. Exploration of Tree-based Hierarchical Softmax for Recurrent Language Models[C]. Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence (IJCAI), 2017, pp. 1951-1957.


Yikang Shen, Wenge Rong, \textbf{Nan Jiang}, Baolin Peng, Jie Tang and Zhang Xiong. Word Embedding Based Correlation Model for Question/Answer Matching[C]. Proceedings of the Thirtieth {AAAI} Conference on Artificial Intelligence (AAAI), 2017, pp. 3511-3517.

\textbf{Nan Jiang}, Wenge Rong, Yifan Nie, Yikang Shen and Zhang Xiong. Event Trigger Identification with Noise Contrastive Estimation[J]. IEEE/ACM Transactions on Computational Biology and Bioinformatics, 2017, pp. 1-11.


\textbf{Nan Jiang}, Wenge Rong, Baolin Peng, Yifan Nie and Zhang Xiong. An Empirical Analysis of Different Sparse Penalties
for Autoencoder in Unsupervised Feature Learning[C]. International Joint Conference on Neural Networks (IJCNN), 2015, pp. 1-8.




\section{Experiences}
{\bf Microsoft Research Asia} \hfill {\bf Dec., 2017 - May., 2018}

{Intern in Speech Group} \\
- Run different embeding models and evaluate its quality; \\
- Use quantization methods to minimize the dumped char-embedding size; \\
- Build the pipeline for Confidence Measures and Rejection Model in OCR System.



{\bf Search Technology Center Asia, Microsoft} \hfill {\bf Dec., 2016 - Sept., 2017}

{Intern in XiaoICE Group} \\
- Clean crawled conversations with regular expression from Reddit;\\
- Investigate current methods to improve neural conversation model;\\
- Attend competitions on Kaggle and contribute different deep models for the tasks.




%{\bf Youdao, Netease}  \hfill {\bf Jun., 2016 - Dec., 2016}
%
%{Intern in Machine Translation Group, Mentor: \underline{\href{http://dblp.uni-trier.de/pers/hd/d/Duan:Yitao}{Yitao Duan}}} \\
%- Investigate recent advances in language models; \\
%- Implement optimizations for RNNLM with large vocabulary; \\
%- Tune the neural machine translation model for online usage.


%{\bf Engineering Research Center}, Beihang University
%
%{\em Research Assistant} \hfill {\bf Sept., 2015 - June, 2016}\\
%Learn the basic theory on DL and implement diverse models on deeplearning.net. Besides, applying these algorithms on semantic analysis and language model.




\section{Selected \\ Awards}
Excellent Graduates of Beijing \hfill {2018} \\
National Scholarship, Ministry of Education \hfill {2017}\\
Quora Question Pairs, Kaggle \hfill {$8^{th}$/3307, 2017}

Highway Tollgates Traffic Flow Prediction, KDD CUP  \hfill {$3^{rd}$/386, 2017}

Travel Grant of IEEE on IJCNN Conference, IEEE Society \hfill { 2015}

Excellent Graduation Paper, ZJUT \hfill {2015}

Outstanding Graduate Student, ZJUT\hfill {2015}

%2012 $\to$ 2014, Zhejiang University of Technology, The First Prize Scholarship

National Scholarship, Ministry of Education \hfill {2011}



%
%\section{Preprint}
%%Sequence Generation with augmented Multi-step Loss. \\
%
%\textbf{Nan Jiang}, Wenge Rong, Min Gao, Yikang Shen and Zhang Xiong. Exploration of Hierarchical Softmax for Recurrent Language Models[J]. ACM Transactions on
%Intelligent Systems and Technology (TIST). (Under Review, Submitted Dec 17, 2017)
%
%Bowen Wu,\textbf{Nan Jiang}, Zhifeng Gao, Wenge Rong and Suke Li. Why Do Neural Response Generation Models Prefer Universal Replies?. (Under review at ACL2018)

\section{ Skills}
\begin{tabular}{@{}p{3.2in}p{4in}}
Programming: C/C++, Python, Java, Matlab;& Tools: Git, Markdown, Bash; \\
\end{tabular}
Language: TOEFL (99), GRE(V: 148, Q: 169, AW: 3.0)

%\section{Activities}
%Attend the IJCNN2015, APBC2017, AAAI2017, IJCAI2017 conference;\\
%Review paper for IEEE Access.

\end{resume}
\end{document}




