\documentclass[margin,line]{resume}
\usepackage[hidelinks]{hyperref}

\begin{document}

\name{Nan Jiang}

\begin{resume}
\section{Contact Information}
\begin{tabular}{@{}p{3in}p{3in}}
School of Computer Science and Engineering & { E-mail:}  {\tt nanjiang@buaa.edu.cn} \\
Beihang University                         & { Blog:} {\tt jiangnanhugo.github.io/blog} \\
Beijing, China                             & { Github:} {\tt github.com/jiangnanhugo} \\
\end{tabular}


\section{Education}
{\bf Beihang University}, Beijing,  CN\\
\emph{MA.Eng.} in Computer Science. Advisor: Wenge Rong.\\
Graduate Design: Exploration of Hierarchical Softmax for Recurrent Language Models. \\
Research Interests: Natural Language Processing, Machine Learning, Deep Learning. \\

{\bf Zhejiang University of Technology}, Zhejiang, CN\\
\emph{B.Eng.} in Computer Science,\space Major GPA: 4.0, Top 1 of 60.


\section{Publications}
\textbf{Nan Jiang}, Wenge Rong, Min Gao, Yikang Shen and Zhang Xiong. Exploration of Tree-based Hierarchical Softmax for Recurrent Language Models[C]. Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence (IJCAI), 2017. [\href{https://github.com/jiangnanHugo/lmkit}{code}][\href{https://www.ijcai.org/proceedings/2017/0271.pdf}{pdf}]


\textbf{Nan Jiang}, Wenge Rong, Yifan Nie, Yikang Shen and Zhang Xiong. Event Trigger Identification with Noise Contrastive Estimation[J]. IEEE/ACM Transactions on Computational Biology and Bioinformatics, 2017. [\href{https://github.com/jiangnanHugo/mlee-nce}{code}][\href{https://github.com/jiangnanhugo/paper/blob/master/APBC2017/APBC2017.pdf}{pdf}]

\textbf{Nan Jiang}, Wenge Rong, Baolin Peng, Yifan Nie and Zhang Xiong. Modeling Joint Representation with Tri-Modal DBNs for Query and Question Matching[J]. IEICE Transactions on Information and Systems.927-935, No. 4, VOL.E99-D.

\textbf{Nan Jiang}, Wenge Rong, Baolin Peng, Yifan Nie and Zhang Xiong. An empirical analysis of different sparse penalties for autoencoder in unsupervised feature learning[C]. International Joint Conference on Neural Networks (IJCNN), 2015.

Yikang Shen, Wenge Rong, \textbf{Nan Jiang}, Baolin Peng, Jie Tang and Zhang Xiong. Word Embedding Based Correlation Model for Question/Answer Matching[C]. Proceedings of the Thirtieth {AAAI} Conference on Artificial Intelligence (AAAI), 2017.


\section{Experiences}
{\bf Microsoft AI and Research Group}, Beijing

{\em NLP Research Intern} \hfill {\bf Dec., 2016 - Sept., 2017}\\
Clean raw text with regular expression from Reddit Website, and build up a corpus to train various neural conversation model (i.e., Seq2Seq model with optimised beam search).\\


{\bf Youdao, Netease Inc.}, Beijing

{\em Machine Translation Research Intern} \hfill {\bf June, 2016 - Dec., 2016}\\
Investigate recent advance in LMs, implement a RNNLM with hierarchical softmax; tune the neural machine translation model with sgd, adadelta and adam algorithms for better BLEU score.


{\bf Engineering Research Center}, Beihang University

{\em Research Assistant} \hfill {\bf Sept., 2015 - June, 2016}\\
Learn the basic theory on DL and implement diverse models on deeplearning.net. Besides, applying these algorithms on semantic analysis and language model.



\section{Competition}
Kaggle - Quora Question Pairs, 2017. 8th; \\
Kaggle - Text Normalization Challenge - English Language, 2017. \\
KDD Cup - Highway Tollgates Traffic Flow Prediction, 2017. 3rd.

\section{Selected \\ Awards}


2017, National Scholarship, Beihang University;

2015 $\to$ 2016, Beihang University, The Second Prize Scholarship

2015, Travel Grant of IEEE on IJCNN Conference, IEEE Society;

2015, Excellent Graduation Paper, Zhejiang University of Technology;

2015, Zhejiang University of Technology, Outstanding Graduate Student

2012 $\to$ 2014, Zhejiang University of Technology, The First Prize Scholarship

2012, National Scholarship, Zhejiang University of Technology.




\section{Computer \\ Skills}
\begin{tabular}{@{}p{3.5in}p{4in}}
Languages: C/C++, Python, Java, Matlab;& Tools: Git, Vim, Markdown, Bash; \\
Libraries: Theano, Lasagne, Tensorflow, Pytorch.  &  \\
\end{tabular}

\section{Activities}
Attend the IJCNN2015, APBC2017, AAAI2017, IJCAI2017 conference;\\
Review paper for IEEE Access.

\section{Unpublished Papers}
Sequence Generation with augmented Multi-step Loss. \\
Why do Neural Response Generation Models prefer Universal Replies? \\

\end{resume}
\end{document}




